{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "import gc\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "gc.enable()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgb(X_fit, y_fit, X_val, y_val, counter, lgb_path, name):\n",
    "    \n",
    "    model = lgb.LGBMClassifier(\n",
    "                               max_depth=-1,\n",
    "                               n_estimators=99999,\n",
    "                               learning_rate=0.05,\n",
    "                               colsample_bytree=0.3,\n",
    "                               num_leaves=2,\n",
    "                               metric='auc',\n",
    "                               objective='binary', \n",
    "                               n_jobs=-1)\n",
    "     \n",
    "    model.fit(X_fit, y_fit, \n",
    "              eval_set=[(X_val, y_val)],\n",
    "              verbose=0, \n",
    "              early_stopping_rounds=1000)\n",
    "                  \n",
    "    cv_val = model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    #Save LightGBM Model\n",
    "    save_to = '{}{}_fold{}.txt'.format(lgb_path, name, counter+1)\n",
    "    model.booster_.save_model(save_to)\n",
    "    \n",
    "    return cv_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_xgb(X_fit, y_fit, X_val, y_val, counter, xgb_path, name):\n",
    "    \n",
    "    model = xgb.XGBClassifier(max_depth=6,\n",
    "                              n_estimators=999,\n",
    "                              colsample_bytree=0.3,\n",
    "                              learning_rate=0.05,\n",
    "                              objective='binary:logistic',\n",
    "                             )\n",
    "     \n",
    "    model.fit(X_fit, y_fit) \n",
    "              #eval_set=[(X_val, y_val)])\n",
    "              #verbose=0) \n",
    "              #early_stopping_rounds=100)\n",
    "              \n",
    "    cv_val = model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    #Save XGBoost Model\n",
    "    save_to = '{}{}_fold{}.dat'.format(xgb_path, name, counter+1)\n",
    "    pickle.dump(model, open(save_to, \"wb\"))\n",
    "    \n",
    "    return cv_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cb(X_fit, y_fit, X_val, y_val, counter, cb_path, name):\n",
    "    \n",
    "    model = cb.CatBoostClassifier(iterations=99999,\n",
    "                                  max_depth=2,\n",
    "                                  learning_rate=0.05,\n",
    "                                  colsample_bylevel=0.03,\n",
    "                                  objective=\"Logloss\")\n",
    "                                  \n",
    "    model.fit(X_fit, y_fit, \n",
    "              eval_set=[(X_val, y_val)], \n",
    "              verbose=0, early_stopping_rounds=1000)\n",
    "              \n",
    "    cv_val = model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    #Save Catboost Model          \n",
    "    save_to = \"{}{}_fold{}.mlmodel\".format(cb_path, name, counter+1)\n",
    "    model.save_model(save_to, format=\"coreml\", \n",
    "                     export_parameters={'prediction_type': 'probability'})\n",
    "                     \n",
    "    return cv_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stage(df_path, lgb_path, xgb_path, cb_path):\n",
    "    \n",
    "    print('Load Train Data.')\n",
    "    df = pd.read_csv(df_path)\n",
    "    print('\\nShape of Train Data: {}'.format(df.shape))\n",
    "    \n",
    "    y_df = np.array(df['target'])                        \n",
    "    df_ids = np.array(df.index)                     \n",
    "    df.drop(['ID_code', 'target'], axis=1, inplace=True)\n",
    "    \n",
    "    lgb_cv_result = np.zeros(df.shape[0])\n",
    "    xgb_cv_result = np.zeros(df.shape[0])\n",
    "    cb_cv_result  = np.zeros(df.shape[0])\n",
    "    #ls_cv_result  = np.zeros(df.shape[0])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    skf.get_n_splits(df_ids, y_df)\n",
    "    \n",
    "    print('\\nModel Fitting...')\n",
    "    for counter, ids in enumerate(skf.split(df_ids, y_df)):\n",
    "        print('\\nFold {}'.format(counter+1))\n",
    "        X_fit, y_fit = df.values[ids[0]], y_df[ids[0]]\n",
    "        X_val, y_val = df.values[ids[1]], y_df[ids[1]]\n",
    "    \n",
    "        print('LigthGBM')\n",
    "        lgb_cv_result[ids[1]] += fit_lgb(X_fit, y_fit, X_val, y_val, counter, lgb_path, name='lgb')\n",
    "        #print('XGBoost')\n",
    "        #xgb_cv_result[ids[1]] += fit_xgb(X_fit, y_fit, X_val, y_val, counter, xgb_path, name='xgb')\n",
    "        print('CatBoost')\n",
    "        cb_cv_result[ids[1]]  += fit_cb(X_fit,  y_fit, X_val, y_val, counter, cb_path,  name='cb')\n",
    "        #ls_cv_result[ids[1]] += fit_lasso(X_fit, y_fit, X_val, y_val, counter, ls_path, name='ls')\n",
    "        \n",
    "        del X_fit, X_val, y_fit, y_val\n",
    "        gc.collect()\n",
    "    \n",
    "    auc_lgb  = round(roc_auc_score(y_df, lgb_cv_result),4)\n",
    "    #auc_xgb  = round(roc_auc_score(y_df, xgb_cv_result),4)\n",
    "    auc_cb   = round(roc_auc_score(y_df, cb_cv_result), 4)\n",
    "    #auc_mean = round(roc_auc_score(y_df, (lgb_cv_result+cb_cv_result+xgb_cv_result)/3), 4)\n",
    "    auc_mean_lgb_cb = round(roc_auc_score(y_df, (lgb_cv_result+cb_cv_result)/2), 4)\n",
    "    print('\\nLightGBM VAL AUC: {}'.format(auc_lgb))\n",
    "    #print('XGBoost  VAL AUC: {}'.format(auc_xgb))\n",
    "    print('Catboost VAL AUC: {}'.format(auc_cb))\n",
    "    print('Mean Catboost+LightGBM VAL AUC: {}'.format(auc_mean_lgb_cb))\n",
    "   # print('Mean XGBoost+Catboost+LightGBM, VAL AUC: {}\\n'.format(auc_mean))\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_stage(df_path, lgb_path, xgb_path, cb_path):\n",
    "    \n",
    "    print('Load Test Data.')\n",
    "    df = pd.read_csv(df_path)\n",
    "    print('\\nShape of Test Data: {}'.format(df.shape))\n",
    "    \n",
    "    df.drop(['ID_code'], axis=1, inplace=True)\n",
    "    \n",
    "    lgb_models = sorted(os.listdir(lgb_path))\n",
    "    #xgb_models = sorted(os.listdir(xgb_path))\n",
    "    cb_models  = sorted(os.listdir(cb_path))\n",
    "    \n",
    "    lgb_result = np.zeros(df.shape[0])\n",
    "    #xgb_result = np.zeros(df.shape[0])\n",
    "    cb_result  = np.zeros(df.shape[0])\n",
    "    \n",
    "    print('\\nMake predictions...\\n')\n",
    "    \n",
    "    print('With LightGBM...')\n",
    "    for m_name in lgb_models:\n",
    "        #Load LightGBM Model\n",
    "        model = lgb.Booster(model_file='{}{}'.format(lgb_path, m_name))\n",
    "        lgb_result += model.predict(df.values)\n",
    "     \n",
    "    #print('With XGBoost...')    \n",
    "    #for m_name in xgb_models:\n",
    "        #Load Catboost Model\n",
    "     #   model = pickle.load(open('{}{}'.format(xgb_path, m_name), \"rb\"))\n",
    "      #  xgb_result += model.predict(df.values)\n",
    "    \n",
    "    print('With CatBoost...')        \n",
    "    for m_name in cb_models:\n",
    "        #Load Catboost Model\n",
    "        model = cb.CatBoostClassifier()\n",
    "        model = model.load_model('{}{}'.format(cb_path, m_name), format = 'coreml')\n",
    "        cb_result += model.predict(df.values, prediction_type='Probability')[:,1]\n",
    "    \n",
    "    lgb_result /= len(lgb_models)\n",
    "    #xgb_result /= len(xgb_models)\n",
    "    cb_result  /= len(cb_models)\n",
    "    \n",
    "    submission = pd.read_csv('./sample_submission.csv')\n",
    "    #submission['target'] = (lgb_result+xgb_result+cb_result)/3\n",
    "    #submission.to_csv('xgb_lgb_cb_starter_submission.csv', index=False)\n",
    "    submission['target'] = (lgb_result+cb_result)/2\n",
    "    submission.to_csv('lgb_cb_starter_submission.csv', index=False)\n",
    "    #submission['target'] = xgb_result\n",
    "    #submission.to_csv('xgb_starter_submission.csv', index=False)\n",
    "    submission['target'] = lgb_result\n",
    "    submission.to_csv('lgb_starter_submission.csv', index=False)\n",
    "    submission['target'] = cb_result\n",
    "    submission.to_csv('cb_starter_submission.csv', index=False)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Stage.\n",
      "\n",
      "Load Train Data.\n",
      "\n",
      "Shape of Train Data: (260294, 418)\n",
      "\n",
      "Model Fitting...\n",
      "\n",
      "Fold 1\n",
      "LigthGBM\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_path = './train_df_f1.csv'\n",
    "    test_path  = './test_df_f1.csv'\n",
    "    \n",
    "    lgb_path = './lgb_models_stack/'\n",
    "    xgb_path = './xgb_models_stack/'\n",
    "    cb_path  = './cb_models_stack/'\n",
    "    ls_path  = './ls_models_stack/'\n",
    "\n",
    "    #Create dir for models\n",
    "    #os.mkdir(lgb_path)\n",
    "    #os.mkdir(xgb_path)\n",
    "    #os.mkdir(cb_path)\n",
    "\n",
    "    print('Train Stage.\\n')\n",
    "    train_stage(train_path, lgb_path, xgb_path, cb_path)\n",
    "    \n",
    "    print('Prediction Stage.\\n')\n",
    "    #prediction_stage(test_path, lgb_path, xgb_path, cb_path)\n",
    "    \n",
    "    print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
